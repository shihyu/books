排序與查找
===============

算法的概念
-----------------

.. index:: s算法, Algorithm

算法（Algorithm）是將一組輸入轉化成一組輸出的一系列計算步驟，其中每個步驟必須能在有限時間內完成。比如 :ref:`func2.recurse` 習題中的Euclid算法，輸入是兩個正整數，輸出是它們的最大公約數，計算步驟是取模、比較等操作，這個算法一定能在有限的步驟和時間內完成（想一想為什麼）。再比如將一組數從小到大排序，輸入是一組原始數據，輸出是排序之後的數據，計算步驟包括比較、移動數據等操作。

算法是用來解決一類計算問題的，注意是一類問題，而不是一個特定的問題。例如，一個排序算法應該能對任意一組數據進行排序，而不是僅對 ``int a[] = { 1, 3, 4, 2, 6, 5 };`` 這樣一組特定的數據排序，如果只需要對這一組數據排序可以寫一個這樣的函數來做：

.. code-block:: c
   :linenos:

   void sort(void)
   {
           a[0] = 1;
           a[1] = 2;
           a[2] = 3;
           a[3] = 4;
           a[4] = 5;
           a[5] = 6;
   }

這顯然不叫算法，因為不具有通用性。由於算法是用來解決一類問題的，它必須能夠正確地解決這一類問題中的任何一個實例，這個算法才是正確的。對於排序算法，任意輸入一組數據，它必須都能輸出正確的排序結果，這個排序算法才是正確的。不正確的算法有兩種可能：一是對於該問題的某些輸入，該算法會無限計算下去，不會終止；二是對於該問題的某些輸入，該算法終止時輸出的是錯誤的結果。有時候不正確的算法也是有用的，如果對於某個問題尋求正確的算法很困難，而某個不正確的算法可以在有限時間內終止，並且能把誤差控制在一定範圍內，那麼這樣的算法也是有實際意義的。例如有時候尋找最優解的開銷很大，往往會選擇能給出次優解的算法。

本章介紹幾種典型的排序和查找算法，並圍繞這幾種算法做時間複雜度分析。學完本章之後如果想進一步學習，可以參考一些全面系統地介紹算法的書，例如 [TAOCP]_ 和 [算法導論]_ 。

.. _sortsearch.insertion:

插入排序
-----------------

.. index:: c插入排序, Insertion Sort

插入排序（Insertion Sort）算法類似於玩撲克時抓牌的過程，玩家每拿到一張牌都要插入到手中已有的牌裡，使之從小到大排好序。例如（該圖出自 [算法導論]_ 的2.1節）：

.. figure:: ../images/sortsearch.sortcards.png

   撲克牌的插入排序

也許你沒有意識到，但其實你的思考過程是這樣的：現在抓到一張7，把它和手裡的牌從右到左依次比較，7比10小，應該再往左插，7比5大，好，就插這裡。為什麼比較了10和5就可以確定7的位置？為什麼不用再比較左邊的4和2呢？因為這裡有一個重要的前提：手裡的牌是已經排好序的。現在我插了7之後，手裡的牌仍然是排好序的，下次再抓到的牌還可以用這個方法插入。

編程對一個數組進行插入排序也是同樣道理，但和插入撲克牌有一點不同，不可能在兩個相鄰的存儲單元之間再插入一個單元，因此要將插入點之後的數據依次往後移動一個單元。排序算法如下：

.. code-block:: c
   :linenos:

   #include <stdio.h>

   #define LEN 5
   int a[LEN] = { 10, 5, 2, 4, 7 };

   void insertion_sort(void)
   {
           int i, j, key;
           for (j = 1; j < LEN; j++) {
                   printf("%d, %d, %d, %d, %d\n",
                          a[0], a[1], a[2], a[3], a[4]);
                   key = a[j];
                   i = j - 1;
                   while (i >= 0 && a[i] > key) {
                           a[i+1] = a[i];
                           i--;
                   }
                   a[i+1] = key;
           }
           printf("%d, %d, %d, %d, %d\n",
                  a[0], a[1], a[2], a[3], a[4]);
   }

   int main(void)
   {
           insertion_sort();
           return 0;
   }

為了更清楚地觀察排序過程，我們在每次循環開頭插了打印語句，在排序結束後也插了打印語句。程序運行結果是::

   $ ./a.out
   10, 5, 2, 4, 7
   5, 10, 2, 4, 7
   2, 5, 10, 4, 7
   2, 4, 5, 10, 7
   2, 4, 5, 7, 10

.. index:: Loop Invariant

如何嚴格證明這個算法是正確的？換句話說，只要反覆執行該算法的 ``for`` 循環體，執行 ``LEN-1`` 次，就一定能把數組 ``a`` 排好序，而不管數組 ``a`` 的原始數據是什麼，如何證明這一點呢？我們可以借助Loop Invariant的概念和數學歸納法來理解循環結構的算法，假如某個判斷條件滿足以下三條準則，它就稱為Loop Invariant：

#. 第一次執行循環體之前該判斷條件為真。
#. 如果“第N-1次循環之後（或者說第N次循環之前）該判斷條件為真”這個前提可以成立，那麼就有辦法證明第N次循環之後該判斷條件仍為真。
#. 如果在所有循環結束後該判斷條件為真，那麼就有辦法證明該算法正確地解決了問題。

只要我們找到這個Loop Invariant，就可以證明一個循環結構的算法是正確的。上述插入排序算法的Loop Invariant是這樣的判斷條件： **第j次循環之前，子序列a[0..j-1]是排好序的。** 下面我們驗證一下Loop Invariant的三條準則：

#. 第一次執行循環之前， ``j=1`` ，子序列 ``a[0..j-1]`` 只有一個元素 ``a[0]`` ，只有一個元素的序列顯然是排好序的。
#. 第 ``j`` 次循環之前，如果“子序列 ``a[0..j-1]`` 是排好序的”這個前提成立，現在要把 ``key=a[j]`` 插進去，按照該算法的步驟，把 ``a[j-1]`` 、 ``a[j-2]`` 、 ``a[j-3]`` 等等比 ``key`` 大的元素都依次往後移一個，直到找到合適的位置將 ``key`` 插入，就能證明循環結束時子序列 ``a[0..j]`` 是排好序的。就像插撲克牌一樣，“手中已有的牌是排好序的”這個前提很重要，如果沒有這個前提，就不能證明再插一張牌之後也是排好序的。
#. 當循環結束時， ``j=LEN`` ，如果“子序列 ``a[0..j-1]`` 是排好序的”這個前提成立，那就是說 ``a[0..LEN-1]`` 是排好序的，也就是說整個數組 ``a`` 的 ``LEN`` 個元素都排好序了。

可見，有了這三條，就可以用數學歸納法證明這個循環是正確的。這和 :ref:`func2.recurse` 證明遞歸程序正確性的思路是一致的，這裡的第一條就相當於遞歸的Base Case，第二條就相當於遞歸的遞推關係。這再次說明了遞歸和循環是等價的。

.. rubric:: 習題

.. index:: x選擇排序, Selection Sort

#. 實現選擇排序（Selection Sort）算法：第一次從數組 ``a[0..LEN-1]`` 中找出最小元素交換到 ``a[0]`` 的位置，第二次從數組 ``a[1..LEN-1]`` 中找出最小元素交換到 ``a[1]`` 的位置，依此類推。排序過程舉例如下::

      10, 5, 2, 4, 7
      2, 5, 10, 4, 7
      2, 4, 10, 5, 7
      2, 4, 5, 10, 7
      2, 4, 5, 7, 10

算法的時間複雜度分析
--------------------------

解決同一個問題可以有很多種算法，比較評價算法的好壞，一個重要的標準就是算法的時間複雜度。現在研究一下插入排序算法的執行時間，按照習慣，輸入長度 ``LEN`` 以下用n表示。設循環中各條語句的執行時間分別是c1、c2、c3、c4、c5這樣五個常數 [#]_ ：

.. index:: s上界, Upper Bound

.. [#] 受內存管理機制的影響，計算機每次執行某一條指令所需的時間不一定相同，但執行某一條指令所需的最長時間是固定的。換句話說，指令的執行時間不一定是常數，但執行時間的上界（Upper Bound）肯定是常數。C語言的每條語句對應若干條計算機指令，我們這裡假設每條語句的執行時間是常數只是一個粗略的估計。

.. code-block:: c
   :linenos:

   void insertion_sort(void)                            執行時間
   {
           int i, j, key;
           for (j = 1; j < LEN; j++) {
                   key = a[j];                          c1
                   i = j - 1;                           c2
                   while (i >= 0 && a[i] > key) {
                           a[i+1] = a[i];               c3
                           i--;                         c4
                   }
                   a[i+1] = key;                        c5
           }
   }

顯然外層 ``for`` 循環的執行次數是n-1次，假設內層的 ``while`` 循環執行m次，則總的執行時間粗略估計是(n-1)×(c1+c2+c5+m×(c3+c4))。當然， ``for`` 和 ``while`` 後面()括號中的賦值和條件判斷的執行也需要時間，而我沒有設一個常數來表示，這不影響我們的粗略估計。

.. index:: x線性函數, Linear Function, z最壞情況, Worst Case

這裡有一個問題，m不是個常數，也不取決於輸入長度n，而是取決於具體的輸入數據。在最好情況下，數組 ``a`` 的原始數據已經排好序了， ``while`` 循環一次也不執行，總的執行時間是(c1+c2+c5)×n-(c1+c2+c5)，可以表示成an+b的形式，是n的線性函數（Linear Function）。那麼在最壞情況（Worst Case）下又如何呢？所謂最壞情況是指數組 ``a`` 的原始數據正好是從大到小排好序的，請讀者想一想為什麼這是最壞情況，然後把上式中的m替換掉算一下執行時間是多少。

.. index:: p平均情況, Average Case, e二次函數, Quadratic Function

數組 ``a`` 的原始數據屬於最好和最壞情況的都比較少見，如果原始數據是隨機的，可稱為平均情況（Average Case）。如果原始數據是隨機的，那麼每次循環將已排序的子序列 ``a[1..j-1]`` 與新插入的元素 ``key`` 相比較，子序列中平均都有一半的元素比 ``key`` 大而另一半比 ``key`` 小，請讀者把上式中的m替換掉算一下執行時間是多少。最後的結論應該是：在最壞情況和平均情況下，總的執行時間都可以表示成an\ :sup:`2`\ +bn+c的形式，是n的二次函數（Quadratic Function）。

在分析算法的時間複雜度時，我們更關心最壞情況而不是最好情況，理由如下：

#. 最壞情況給出了算法執行時間的上界，我們可以確信，無論給什麼輸入，算法的執行時間都不會超過這個上界，這樣為比較和分析提供了便利。
#. 對於某些算法，最壞情況是最常發生的情況，例如在資料庫中查找某個信息的算法，最壞情況就是資料庫中根本不存在該信息，都找遍了也沒有，而某些應用場合經常要查找一個信息在資料庫中存在不存在。

比較兩個多項式a\ :sub:`1`\ n+b\ :sub:`1` 和a\ :sub:`2`\ n\ :sup:`2`\ +b\ :sub:`2`\ n+c\ :sub:`2` 的值（n取正整數）可以得出結論：n的最高次指數是最主要的決定因素，常數項、低次冪項和係數都是次要的。比如100n+1和n\ :sup:`2`\ +1，雖然後者的係數小，當n較小時前者的值較大，但是當n>100時，後者的值就遠遠大於前者了。如果同一個問題可以用兩種算法解決，其中一種算法的時間複雜度是線性函數，另一種算法的時間複雜度是二次函數，當問題的輸入長度n足夠大時，前者明顯優於後者。因此我們可以用一種更粗略的方式表示算法的時間複雜度，把係數和低次冪項都省去，線性函數記作Θ(n)，二次函數記作Θ(n\ :sup:`2`)。

Θ(g(n))表示和g(n)同一量級的一類函數。比如g(n)=n\ :sup:`2` ，所有的二次函數（例如f(n)=1/2n\ :sup:`2`\ -3n）都和g(n)屬於同一量級，甚至有些不是二次函數的函數（例如f(n)=2n\ :sup:`2`\ +3lgn）也和g(n)屬於同一量級，它們都可以用Θ(g(n))（即Θ(n\ :sup:`2`)）來表示。“同一量級”這個概念可以用下圖來說明（該圖出自 [算法導論]_ 的3.1節）：

.. index:: Θ-notation

.. figure:: ../images/sortsearch.theta.png

   Θ-notation

如果可以找到兩個正的常數c\ :sub:`1` 、 c\ :sub:`2` 和常數n\ :sub:`0` ，使得n≥n\ :sub:`0` （也就是n足夠大）的時候f(n)總是夾在c\ :sub:`1`\ g(n)和c\ :sub:`2`\ g(n)之間，就說f(n)和g(n)是同一量級的，f(n)就可以用Θ(g(n))來表示。

以二次函數為例，比如1/2n\ :sup:`2`\ -3n，要證明它屬於Θ(n\ :sup:`2`)這一類函數的集合，我們必須確定c\ :sub:`1` 、c\ :sub:`2` 和n\ :sub:`0` ，這些常數不隨n改變，並且當n≥n\ :sub:`0` 時c\ :sub:`1`\ n\ :sup:`2`\ ≤1/2n\ :sup:`2` -3n≤c\ :sub:`2`\ n\ :sup:`2` 總是成立的。為此我們從不等式的每一邊都除以n\ :sup:`2` ，得到c\ :sub:`1`\ ≤1/2-3/n≤c\ :sub:`2` 。函數1/2-3/n的曲綫見下圖：

.. figure:: ../images/sortsearch.fn0.png

   1/2-3/n

這樣就很容易看出來，無論n取多少，該函數一定小於1/2，因此c\ :sub:`2`\ =1/2。當n=6時函數值為0，n>6時該函數都大於0，可以取n\ :sub:`0`\ =7，c\ :sub:`1`\ =1/14，這樣當n≥n\ :sub:`0` 時都有1/2-3/n≥c\ :sub:`1`。通過這個證明過程可以得出結論，當n足夠大時任何an\ :sup:`2`\ +bn+c都夾在c\ :sub:`1`\ n\ :sup:`2` 和c\ :sub:`2`\ n\ :sup:`2` 之間，相對於n\ :sup:`2` 項來說bn+c的影響可以忽略，a可以通過選取合適的c\ :sub:`1` 、c\ :sub:`2` 來補償。

幾種常見的時間複雜度函數按數量級從小到大的順序依次是：Θ(lgn)，Θ(sqrt(n))，Θ(n)，Θ(nlgn)，Θ(n\ :sup:`2`)，Θ(n\ :sup:`3`)，Θ(2\ :sup:`n`)，Θ(n!)。其中，lgn通常表示以10為底n的對數，但是對於Θ-notation來說Θ(lgn)和Θ(log\ :sub:`2`\ n)並無區別（想一想這是為什麼），因而在算法分析中lgn通常表示以2為底n的對數。可是什麼算法的時間複雜度裡會出現lgn呢？回顧插入排序的時間複雜度分析，無非是循環體的執行時間乘以循環次數，只有加和乘運算，怎麼會出來lg呢？下一節歸併排序的時間複雜度裡面就有lg，請讀者留心lg運算是從哪出來的。

.. index:: Big-O notation

除了Θ-notation之外，表示算法的時間複雜度常用的還有一種Big-O notation。我們知道插入排序在最壞情況和平均情況下時間複雜度是Θ(n\ :sup:`2`)，在最好情況下是Θ(n)（數量級比Θ(n\ :sup:`2`)要小），那麼總結起來在各種情況下插入排序的時間複雜度是O(n\ :sup:`2`)。Θ的含義和“等於”類似，而大O的含義和“小於等於”類似。

.. _sortsearch.mergesort:

歸併排序
------------------

.. index:: z增量式, Incremental, f分而治之, Diviade-and-Conquer

插入排序算法採取增量式的策略解決問題，每次添一個元素到已排序的子序列中，逐漸將整個數組排序完畢，它的時間複雜度是O(n\ :sup:`2`)。下面介紹另一種典型的排序算法－－歸併排序，它採取分而治之（Divide-and-Conquer）的策略，時間複雜度是Θ(nlgn)。歸併排序的步驟如下：

#. Divide: 把長度為n的輸入序列分成兩個長度為n/2的子序列。
#. Conquer: 對這兩個子序列分別採用歸併排序。
#. Combine: 將兩個排序好的子序列合併成一個最終的排序序列。

在描述歸併排序的步驟時又調用了歸併排序本身，可見這是一個遞歸的過程。

.. code-block:: c
   :linenos:

   #include <stdio.h>

   #define LEN 8
   int a[LEN] = { 5, 2, 4, 7, 1, 3, 2, 6 };

   void merge(int start, int mid, int end)
   {
           int n1 = mid - start + 1;
           int n2 = end - mid;
           int left[n1], right[n2];
           int i, j, k;

           for (i = 0; i < n1; i++) /* left holds a[start..mid] */
                   left[i] = a[start+i];
           for (j = 0; j < n2; j++) /* right holds a[mid+1..end] */
                   right[j] = a[mid+1+j];

           i = j = 0;
           k = start;
           while (i < n1 && j < n2)
                   if (left[i] < right[j])
                           a[k++] = left[i++];
                   else
                           a[k++] = right[j++];

           while (i < n1) /* left[] is not exhausted */
                   a[k++] = left[i++];
           while (j < n2) /* right[] is not exhausted */
                   a[k++] = right[j++];
   }

   void sort(int start, int end)
   {
           int mid;
           if (start < end) {
                   mid = (start + end) / 2;
                   printf("sort (%d-%d, %d-%d) %d %d %d %d %d %d %d %d\n", 
                          start, mid, mid+1, end, 
                          a[0], a[1], a[2], a[3], a[4], a[5], a[6], a[7]);
                   sort(start, mid);
                   sort(mid+1, end);
                   merge(start, mid, end);
                   printf("merge (%d-%d, %d-%d) to %d %d %d %d %d %d %d %d\n", 
                          start, mid, mid+1, end, 
                          a[0], a[1], a[2], a[3], a[4], a[5], a[6], a[7]);
           }
   }

   int main(void)
   {
           sort(0, LEN-1);
           return 0;
   }

執行結果是::

   sort (0-3, 4-7) 5 2 4 7 1 3 2 6
   sort (0-1, 2-3) 5 2 4 7 1 3 2 6
   sort (0-0, 1-1) 5 2 4 7 1 3 2 6
   merge (0-0, 1-1) to 2 5 4 7 1 3 2 6
   sort (2-2, 3-3) 2 5 4 7 1 3 2 6
   merge (2-2, 3-3) to 2 5 4 7 1 3 2 6
   merge 0-1, 2-3) to 2 4 5 7 1 3 2 6
   sort (4-5, 6-7) 2 4 5 7 1 3 2 6
   sort (4-4, 5-5) 2 4 5 7 1 3 2 6
   merge (4-4, 5-5) to 2 4 5 7 1 3 2 6
   sort (6-6, 7-7) 2 4 5 7 1 3 2 6
   merge (6-6, 7-7) to 2 4 5 7 1 3 2 6
   merge (4-5, 6-7) to 2 4 5 7 1 2 3 6
   merge (0-3, 4-7) to 1 2 2 3 4 5 6 7

``sort`` 函數把 ``a[start..end]`` 平均分成兩個子序列，分別是 ``a[start..mid]`` 和 ``a[mid+1..end]`` ，對這兩個子序列分別遞歸調用 ``sort`` 函數進行排序，然後調用 ``merge`` 函數將排好序的兩個子序列合併起來。由於兩個子序列都已經排好序了，合併的過程很簡單，每次循環取兩個子序列中最小的元素進行比較，將較小的元素取出放到最終的排序序列中，如果其中一個子序列的元素已取完，就把另一個子序列剩下的元素都放到最終的排序序列中。為了便於理解程序，我在 ``sort`` 函數開頭和結尾插了打印語句，可以看出調用過程是這樣的：

.. figure:: ../images/sortsearch.mergesort.png

   歸併排序調用過程

圖中S表示 ``sort`` 函數，M表示 ``merge`` 函數，整個控制流程沿虛線所示的方向調用和返回。由於 ``sort`` 函數遞歸調用了自己兩次，所以各函數之間的調用關係呈樹狀結構。畫這個圖只是為了清楚地展現歸併排序的過程，讀者在理解遞歸函數時一定不要全部展開來看，而是要抓住Base Case和遞推關係來理解。下面我們分析歸併排序的時間複雜度，以下分析出自 [算法導論]_ 的2.3節。

首先分析 ``merge`` 函數的時間複雜度。在 ``merge`` 函數中演示了C99的新特性－－可變長數組，當然也可以避免使用這一特性，比如把 ``left`` 和 ``right`` 都按最大長度 ``LEN`` 分配。不管用哪種辦法，“定義數組並分配存儲空間”這個操作的執行時間都可以看作常數，與數組的長度無關，常數用Θ-notation記作Θ(1)。設子序列 ``a[start..mid]`` 的長度為n1，子序列 ``[mid+1..end]`` 的長度為n2， ``a[start..end]`` 的總長度為n=n1+n2，則前兩個 ``for`` 循環的執行時間是Θ(n1+n2)，也就是Θ(n)，後面三個 ``for`` 循環合在一起看，每走一次循環就會在最終的排序序列中確定一個元素，最終的排序序列共有n個元素，所以執行時間也是Θ(n)。兩個Θ(n)再加上若干常數項， ``merge`` 函數總的執行時間仍是Θ(n)，其中n=end-start+1。

然後分析 ``sort`` 函數的時間複雜度。當輸入長度n=1，也就是 ``start==end`` 時， ``if`` 條件不成立，執行時間為常數Θ(1)。當輸入長度n>1時：

   總的執行時間 = 2 × 輸入長度為n/2的 ``sort`` 函數的執行時間 + ``merge`` 函數的執行時間Θ(n)

設輸入長度為n的 ``sort`` 函數的執行時間為T(n)，綜上所述：

.. figure:: ../images/sortsearch.recurrence1.png

.. index:: d遞推公式, Recurrence

這是一個遞推公式（Recurrence），我們需要消去等號右側的T(n)，把T(n)寫成n的函數。其實符合一定條件的Recurrence的展開有數學公式可以套，這裡我們略去嚴格的數學證明，只是從直觀上看一下這個遞推公式的結果。當n=1時可以設T(1)=c\ :sub:`1` ，當n>1時可以設T(n)=2T(n/2)+c\ :sub:`2`\ n，我們取c\ :sub:`1` 和c\ :sub:`2` 中較大的一個設為c，把原來的公式改為：

.. figure:: ../images/sortsearch.recurrence2.png

這樣計算出的結果應該是T(n)的上界。下面我們把T(n/2)展開成2T(n/4)+cn/2（下圖中的(c)），然後再把T(n/4)進一步展開，直到最後全部變成T(1)=c（下圖中的(d)）：

.. figure:: ../images/sortsearch.calcrecurrence.png

   歸併排序算法的時間複雜度分析

把圖(d)中所有的項加起來就是總的執行時間。這是一個樹狀結構，每一層的和都是cn，共有lgn+1層，因此總的執行時間是cnlgn+cn，相比nlgn來說，cn項可以忽略，因此T(n)的上界是Θ(nlgn)。

如果先前取c\ :sub:`1` 和c\ :sub:`2` 中較小的一個設為c，計算出的結果應該是T(n)的下界，然而推導過程一樣，結果也是Θ(nlgn)。既然T(n)的上下界都是Θ(nlgn)，顯然T(n)就是Θ(nlgn)。

和插入排序的平均情況相比歸併排序更快一些，雖然 ``merge`` 函數的步驟較多，引入了較大的常數、係數和低次項，但是對於較大的輸入長度n，這些都不是主要因素，歸併排序的時間複雜度是Θ(nlgn)，而插入排序在平均情況下是Θ(n\ :sup:`2`)，這就決定了歸併排序是更快的算法。那麼是不是任何情況下歸併排序都優於插入排序呢？哪些情況適用插入排序而不適用歸併排序？留給讀者思考。

.. rubric:: 習題

#. 快速排序是另外一種採用分而治之策略的排序算法，在平均情況下的時間複雜度也是Θ(nlgn)，但比歸併排序有更小的時間常數。它的基本思想是這樣的：

   .. code-block:: c
      :linenos:

      int partition(int start, int end)
      {
              從a[start..end]中選取一個pivot元素（比如選a[start]為pivot）;
              在一個循環中移動a[start..end]的數據，將a[start..end]分成兩部分，
              使a[start..mid-1]比pivot元素小，a[mid+1..end]比pivot元素大，而a[mid]就是pivot元素;
              return mid;
      }

      void quicksort(int start, int end)
      {
              int mid;
              if (end > start) {
                      mid = partition(start, end);
                      quicksort(start, mid-1);
                      quicksort(mid+1, end);
              }
      }

   請補完 ``partition`` 函數，這個函數有多種寫法，請選擇時間常數儘可能小的實現方法。想想快速排序在最好和最壞情況下的時間複雜度分別是多少？快速排序在平均情況下的時間複雜度分析起來比較複雜，有興趣的讀者可以參考 [算法導論]_ 的7.4.2節。

#. 總結一下我們見過的算法，哪些算法在平均情況和最壞情況下的時間複雜度差不多？哪些算法在平均情況和最好情況下的時間複雜度差不多？哪些算法的時間複雜度是固定的，分不出最好情況、最壞情況和平均情況？

線性查找
----------------

有些查找問題要用時間複雜度為O(n)的算法來解決。例如寫一個 ``indexof`` 函數，從任意的輸入字元串中找出某個字母首次出現的位置並返回這個位置，如果找不到就返回-1：

.. code-block:: c
   :linenos:

   #include <stdio.h>

   char a[]="hello world";

   int indexof(char letter)
   {
           int i = 0;
           while (a[i] != '\0') {
                   if (a[i] == letter)
                           return i;
                   i++;
           }
           return -1;
   }

   int main(void)
   {
           printf("%d %d\n", indexof('o'), indexof('z'));
           return 0;
   }


這個實現是最直觀和最容易想到的，但它是不是最快的算法呢？我們知道插入排序也比歸併排序更容易想到，但通常不如歸併排序快。那麼現在這個問題－－給定一個隨機排列的序列，找出其中某個元素的位置－－有沒有比O(n)更快的算法？比如O(lgn)？請讀者思考一下。

.. rubric:: 習題

.. index:: k-th Order Statistic

#. 實現一個算法，在一組隨機排列的數中找出最小的一個。你能想到的最直觀的算法一定是Θ(n)的，想想有沒有比Θ(n)更快的算法？

#. 在一組隨機排列的數中找出第二小的，這個問題比上一個稍複雜，你能不能想出Θ(n)的算法？

#. 進一步泛化，在一組隨機排列的數中找出第k小的，這個元素稱為k-th Order Statistic。能想到的最直觀的算法肯定是先把這些數排序然後取第k個，時間複雜度和排序算法相同，可以是Θ(nlgn)。這個問題雖然比前兩個問題複雜，但它也有平均情況下時間複雜度是Θ(n)的算法，將上一節習題中的快速排序算法稍加修改就可以解決這個問題：

   .. code-block:: c
      :linenos:

      /* 第k小的元素在start和end之間，找出並返回該元素 */
      int order_statistic(int start, int end, int k)
      {
              用partition函數把序列分成兩部分，中間的pivot元素是序列中的第i個;
              if (k == i)
                      返回找到的元素;
              else if (k > i)
                      第k小的元素在序列後半部分，找出並返回該元素;
              else
                      第k小的元素在序列前半部分，找出並返回該元素;
      }

   請編程實現這個算法。

.. _sortsearch.binarysearch:

折半查找
------------------

如果不是從一組隨機的序列裡查找，而是從一組排好序的序列裡找出某個元素的位置，則可以有更快的算法：

.. code-block:: c
   :linenos:

   #include <stdio.h>

   #define LEN 8
   int a[LEN] = { 1, 2, 2, 2, 5, 6, 8, 9 };

   int binarysearch(int number)
   {
           int mid, start = 0, end = LEN - 1;

           while (start <= end) {
                   mid = (start + end) / 2;
                   if (a[mid] < number)
                           start = mid + 1;
                   else if (a[mid] > number)
                           end = mid - 1;
                   else
                           return mid;
           }
           return -1;
   }

   int main(void)
   {
           printf("%d\n", binarysearch(5));
           return 0;
   }

.. index:: z折半查找, Binary Search

由於這個序列已經從小到大排好序了，每次取中間的元素和待查找的元素比較，如果中間的元素比待查找的元素小，就說明“如果待查找的元素存在，一定位於序列的後半部分”，這樣可以把搜索範圍縮小到後半部分，然後再次使用這種算法迭代。這種“每次將搜索範圍縮小一半”的思想稱為折半查找（Binary Search）。思考一下，這個算法的時間複雜度是多少？

這個算法的思想很簡單，不是嗎？可是 [編程珠璣]_ 的4.1節說作者在課堂上講完這個算法的思想然後讓學生寫程序，有90%的人寫出的程序中有各種各樣的Bug，讀者不信的話可以不看書自己寫一遍試試。這個算法容易出錯的地方很多，比如 ``mid = (start + end) / 2;`` 這一句，在數學概念上其實是mid = ⌊(start + end) / 2⌋，還有 ``start = mid + 1;`` 和 ``end = mid - 1;`` ，如果前者寫成了start = mid;或後者寫成了end = mid;那麼很可能會導致死循環（想一想什麼情況下會死循環）。

怎樣才能保證程序的正確性呢？在 :ref:`sortsearch.insertion` 我們講過借助Loop Invariant證明循環的正確性， ``binarysearch`` 這個函數的主體也是一個循環，它的Loop Invariant可以這樣描述： **待查找的元素number如果存在於數組a之中，那麼一定存在於a[start..end]這個範圍之間，換句話說，在這個範圍之外的數組a的元素中一定不存在number這個元素。** 以下為了書寫方便，我們把這句話表示成 ``mustbe(start, end, number)`` 。可以一邊看算法一邊做推理：

.. code-block:: c
   :linenos:

   int binarysearch(int number)
   {
           int mid, start = 0, end = LEN - 1;

           /* 假定a是排好序的 */
           /* mustbe(start, end, number)，因為a[start..end]就是整個數組a[0..LEN-1] */
           while (start <= end) {
           /* mustbe(start, end, number)，因為一開始進入循環時是正確的，每次循環也都維護了這個條件 */
                   mid = (start + end) / 2;
                   if (a[mid] < number)
                           /* 既然a是排好序的，a[start..mid]應該都比number小，所以mustbe(mid+1, end, number) */
                           start = mid + 1;
                           /* 維護了mustbe(start, end, number) */
                   else if (a[mid] > number)
                           /* 既然a是排好序的，a[mid..end]應該都比number大，所以mustbe(start, mid-1, number) */
                           end = mid - 1;
                           /* 維護了mustbe(start, end, number) */
                   else
                           /* a[mid] == number，說明找到了 */
                           return mid;
           }
           /* 
            * mustbe(start, end, number)一直被循環維護着，到這裡應該仍然成立，在a[start..end]範圍之外一定不存在number，
            * 但現在a[start..end]是空序列，在這個範圍之外的正是整個數組a，因此整個數組a中都不存在number
            */
           return -1;
   }

.. index:: d調用者, Caller, b被調用者, s實現者, Callee, q契約, Contract, Precondition, w維護, Maintenance, Postcondition, Design by Contract, DbC

注意這個算法有一個非常重要的前提－－ ``a`` 是排好序的。缺了這個前提，“如果 ``a[mid] < number`` ，那麼 ``a[start..mid]`` 應該都比 ``number`` 小”這一步推理就不能成立，這個函數就不能正確地完成查找。從更普遍的意義上說，函數的調用者（Caller）和函數的實現者（Callee，被調用者）之間訂立了一個契約（Contract），在調用函數之前，Caller要為Callee提供某些條件，比如確保 ``a`` 是排好序的，確保 ``a[start..end]`` 都是有效的數組元素而沒有訪問越界，這稱為Precondition，然後Callee對一些Invariant進行維護（Maintenance），這些Invariant保證了Callee在函數返回時能夠對Caller盡到某些義務，比如確保“如果 ``number`` 在數組 ``a`` 中存在，一定能找出來並返回它的位置；如果 ``number`` 在數組 ``a`` 中不存在，一定能返回-1”，這稱為Postcondition。如果每個函數的文檔都非常清楚地記錄了Precondition、Maintenance和Postcondition是什麼，那麼每個函數都可以獨立編寫和測試，整個系統就會易於維護。這種編程思想是由Eiffel語言的設計者Bertrand Meyer提出來的，稱為Design by Contract（DbC）。

測試一個函數是否正確需要把Precondition、Maintenance和Postcondition這三方面都測試到，比如 ``binarysearch`` 這個函數，即使它寫得非常正確，既維護了Invariant也保證了Postcondition，如果調用它的Caller沒有保證Precondition，最後的結果也還是錯的。我們編寫幾個測試用的Predicate函數，然後把相關的測試插入到 ``binarysearch`` 函數中：

.. code-block:: c
   :linenos:

   #include <stdio.h>
   #include <assert.h>

   #define LEN 8
   int a[LEN] = { 1, 2, 2, 2, 5, 6, 8, 9 };

   int is_sorted(void)
   {
           int i;
           for (i = 1; i < LEN; i++)
                   if (a[i-1] > a[i])
                           return 0;
           return 1;
   }

   int mustbe(int start, int end, int number)
   {
           int i;
           for (i = 0; i < start; i++)
                   if (a[i] == number)
                           return 0;
           for (i = end+1; i < LEN; i++)
                   if (a[i] == number)
                           return 0;
           return 1;
   }

   int contains(int n)
   {
           int i;
           for (i = 0; i < LEN; i++)
                   if (a[i] == n)
                           return 1;
           return 0;
   }

   int binarysearch(int number)
   {
           int mid, start = 0, end = LEN - 1;

           assert(is_sorted()); /* Precondition */
           while (start <= end) {
                   assert(mustbe(start, end, number)); /* Maintenance */
                   mid = (start + end) / 2;
                   if (a[mid] < number)
                           start = mid + 1;
                   else if (a[mid] > number)
                           end = mid - 1;
                   else {
                           assert(mid >= start && mid <= end
                                  && a[mid] == number); /* Postcondition 1 */
                           return mid;
                   }
           }
           assert(!contains(number)); /* Postcondition 2 */
           return -1;
   }

   int main(void)
   {
           printf("%d\n", binarysearch(5));
           return 0;
   }


``assert`` 是標頭檔 :file:`assert.h` 中的一個宏定義，執行到 ``assert(is_sorted())`` 這句時，如果 ``is_sorted()`` 返回值為真，則當什麼事都沒發生過，繼續往下執行，如果 ``is_sorted()`` 返回值為假（例如把數組的排列順序改一改），則報錯退出程序::

   $ ./a.out 
   a.out: main.c:41: binarysearch: Assertion `is_sorted()' failed.
   Aborted (core dumped)

.. index:: d斷言, Assertion

在代碼中適當的地方使用斷言（Assertion）可以有效地幫助我們測試程序。也許有人會問：我們用幾個測試函數來測試 ``binarysearch`` ，那麼這幾個測試函數又用什麼來測試呢？在實際工作中我們要測試的代碼絶不會像 ``binarysearch`` 這麼簡單，而我們編寫的測試函數往往都很簡單，比較容易保證正確性，也就是用簡單的、不容易出錯的代碼去測試複雜的、容易出錯的代碼。

.. index:: f發佈, Release

測試代碼只在開發和調試時有用，如果正式發佈（Release）的軟件也要運行這些測試代碼就會嚴重影響性能了，如果在包含 :file:`assert.h` 之前定義一個 ``NDEBUG`` 宏（表示No Debug），就可以禁用 :file:`assert.h` 中的 ``assert`` 宏定義，這樣代碼中的所有 ``assert`` 測試都不起作用了：

.. code-block:: c
   :linenos:

   #define NDEBUG
   #include <stdio.h>
   #include <assert.h>
   ...

注意 ``NDEBUG`` 和我們以前使用的宏定義有點不同，例如 ``#define N 20`` 將 ``N`` 定義為 ``20`` ，在預處理時把代碼中所有的標識符 ``N`` 替換成 ``20`` ，而 ``#define NDEBUG`` 把 ``NDEBUG`` 定義為空，在預處理時把代碼中所有的標識符 ``NDEBUG`` 替換成空。這樣的宏定義主要是為了用 ``#ifdef`` 等預處理指示測試它定義過沒有，而不是為了做替換，所以定義成什麼值都無所謂，一般定義成空就足夠了。

還有另一種辦法，不必修改源檔案，在編譯命令行加上選項 :option:`-DNDEBUG` 就相當於在源檔案開頭定義了 ``NDEBUG`` 宏。宏定義和預處理到 :doc:`prep` 再詳細解釋，在 :ref:`prep.otherfeature` 將給出 :file:`assert.h` 的一種實現。

.. rubric:: 習題

#. 本節的折半查找算法有一個特點：如果待查找的元素在數組中有多個則返回其中任意一個，以本節定義的數組 ``int a[8] = { 1, 2, 2, 2, 5, 6, 8, 9 };`` 為例，如果調用 ``binarysearch(2)`` 則返回3，即 ``a[3]`` ，而有些場合下要求這樣的查找返回 ``a[1]`` （如果待查找的元素在數組中有多個則返回第一個）。請修改折半查找算法實現這一特性。

#. 編寫一個函數 ``double mysqrt(double y)`` 求 ``y`` 的正平方根，參數 ``y`` 是正實數。我們用折半查找來找這個平方根，在從0到y之間必定有一個取值是y的平方根，如果我們查找的數x比y的平方根小，則x\ :sup:`2`\ <y，如果我們查找的數x比y的平方根大，則x\ :sup:`2`\ >y，我們可以據此縮小查找範圍，當我們查找的數足夠準確時（比如滿足|x2-y|<0.001），就可以認為找到了y的平方根。思考一下這個算法需要迭代多少次？迭代次數的多少由什麼因素決定？

#. 編寫一個函數 ``double mypow(double x, int n)`` 求 ``x`` 的 ``n`` 次方，參數 ``n`` 是正整數。最簡單的算法是：

   .. code-block:: c
      :linenos:

      double product = 1;
      for (i = 0; i < n; i++)
              product *= x;

   這個算法的時間複雜度是Θ(n)。其實有更好的辦法，比如 ``mypow(x, 8)`` ，第一次循環算出x·x=x\ :sup:`2` ，第二次循環算出x\ :sup:`2`\ ·x\ :sup:`2`\ =x\ :sup:`4` ，第三次循環算出x\ :sup:`4`\ ·x\ :sup:`4`\ =x\ :sup:`8` 。這樣只需要三次循環，時間複雜度是Θ(lgn)。思考一下如果n不是2的整數次冪應該怎麼處理。請分別用遞歸和循環實現這個算法。

從以上幾題可以看出，折半查找的思想有非常廣泛的應用，不僅限于從一組排好序的元素中找出某個元素的位置，還可以解決很多類似的問題。 [編程珠璣]_ 對於折半查找的各種應用和優化技巧有非常詳細的介紹。
